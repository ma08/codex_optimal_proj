["from re import sub\n\nignoreList = [\"THE\", \"OF\", \"IN\", \"FROM\", \"BY\", \"WITH\", \"AND\",  \"OR\",  \"FOR\",  \"TO\",  \"AT\",  \"A\"]\n\ndef generate_bc(url, separator):\n    # remove leading http(s):// and trailing /\n    url = sub(\"https?://\", \"\", url.strip(\"/\"))\n    \n    # skip index files\n    url = sub(\"/index\\..+$\", \"\", url)\n    \n    # split url for processing\n    url = url.split(\"/\")\n    \n    # remove file extensions, anchors and parameters\n    url[-1] = sub(\"[\\.#\\?].*\", \"\", url[-1])\n    \n    # first element is always \"home\"\n    menu = [\"HOME\"]\n    # generate breadcrumb items\n    for item in url[1:]:\n        # replace dashes and set to uppercase\n        item = sub(\"-\", \" \", item.upper())\n        # create acronym if too long\n        if len(item) > 30:\n            item = \"\".join([w[0] for w in item.split() if w not in ignoreList])\n        menu.append(item)\n    \n    # generate paths\n    path = [\"/\"]\n    for i in range(len(url) - 1):\n        path.append(path[i] + url[i+1] + \"/\")\n    \n    # generate html code\n    html = []\n    for i in range(len(url) - 1):\n        html.append(\"<a href=\\\"\" + path[i] + \"\\\">\" + menu[i] +\"</a>\")\n    html.append(\"<span class=\\\"active\\\">\" + menu[-1] +\"</span>\")\n    \n    return separator.join(html)", "common_extensions = [\"html\", \"htm\", \"php\", \"asp\", \"jsp\"]\nacronym_ignore = [\"the\",\"of\",\"in\",\"from\",\"by\",\"with\",\"and\", \"or\", \"for\", \"to\", \"at\", \"a\"]\nprotocols = [\"http://\", \"https://\"]\nhome_tpl = \"<a href=\\\"/\\\">HOME</a>\"\nspan_tpl = \"<span class=\\\"active\\\">%s</span>\"\nlink_tpl = \"<a href=\\\"%s\\\">%s</a>\"\n\n\ndef generate_bc(url, separator):\n    \"\"\"\n    Turn an url into an html breadcrumb\n    \"\"\"\n    print url\n    url = no_protocol(url)\n    bread = home_tpl\n    crumbs = url.split(\"/\")[1:]\n    crumbs = [c for c in crumbs if not(is_index(c)) and len(c) > 0]\n    previous = \"/\"\n    print crumbs\n    if len(crumbs) == 0:\n        return \"<span class=\\\"active\\\">HOME</span>\"\n    for crumb in crumbs[:-1]:\n        previous, html = knead(crumb, previous)\n        bread += separator + html\n    bread += separator + brown(crumbs[-1])\n    return bread\n\n\ndef knead(crumb, previous):\n    \"\"\"\n    Turn a crumb into breadcrumb element\n    :param crumb Url part to turn into breadcrumb part\n    :param previous url part if any\n    :return Tuple containing url and html Breadcrumb element (url, html)\n    \"\"\"\n    assert type(crumb) is str\n    assert type(previous) is str\n    crumb = no_extension(no_params(crumb))\n    url = previous + crumb + \"/\" \n    name = to_acronym(crumb, \"\", 30)\n    name = name.upper()\n    return url, link_tpl % (url, name)\n\n\ndef brown(crumb):\n    \"\"\"\n    Brown the last crumb into an active span\n    :param url_part URL part to check\n    :return HTML active span for the crumb\n    \"\"\"\n    assert type(crumb) is str\n    name = to_acronym(no_extension(no_anchor(no_params(crumb))), \" \", 30)\n    return span_tpl % (name.upper())\n\n\ndef to_acronym(url_part, joiner, max):\n    \"\"\"\n    Turn the given string into an acronym if the size > :max\n    :param url_part URL part to check\n    :param joiner char to place between word\n    :max max number of letter allowed before turning the string into an acronym\n    :return Name or acronym if size is too big\n    \"\"\"\n    assert type(url_part) is str\n    assert type(joiner) is str\n    assert type(max) is int\n    if len(url_part) >= max:\n        url_part=\"\".join([word[0] for word in url_part.split(\"-\") if word not in acronym_ignore])\n    return url_part.replace(\"-\", \" \")\n\n\ndef is_index(url_part):\n    \"\"\"\n    Check if url part is index\n    :param url_part URL part to check\n    :return True if the name of the element is index.something\n    \"\"\"\n    assert type(url_part) is str\n    return \"index\" in url_part\n\n\ndef no_extension(url_part):\n    \"\"\"\n    Remove common extension from the end of the url part\n    :param url_part URL part to treat\n    :return url part as a string without any known extension\n    \"\"\"\n    assert type(url_part) is str\n    splitted = url_part.split(\".\")\n    if splitted[-1] in common_extensions:\n        splitted = splitted[:-1]\n    return '.'.join(splitted)\n    \n    \ndef no_params(url_part):\n    \"\"\"\n    Remove uri params\n    :param url_part URL part to treat\n    :return url part as a string without uri params\n    \"\"\"\n    assert type(url_part) is str\n    return url_part.split(\"?\")[0]\n    \n\ndef no_protocol(url):\n    \"\"\"\n    Remove protocol from url string\n    :param url URL to strip\n    :return URL string without protocol\n    \"\"\"\n    assert type(url) is str\n    for p in protocols:\n        if url.startswith(p):\n            url = url[len(p):]\n    return url\n    \n\ndef no_anchor(url_part):\n    \"\"\"\n    Remove anchor from url\n    :param url_part URL part to treat\n    :return url part as a string without anchor\n    \"\"\"\n    assert type(url_part) is str\n    return url_part.split(\"#\")[0]", "import re\n\nINVALID_WORDS = set(\"the of in from by with and or for to at a\".upper().split())\n\ndef formater(part):\n    part = part.replace(\"-\",\" \").upper()\n    if len(part) > 30: part = ''.join( w[0] for w in part.split() if w not in INVALID_WORDS )\n    return part\n    \ndef generate_bc(url, separator):\n    ans, urlLst = [], re.sub(r'(/index\\..*)|(\\?.*)|(#.*)|(https?://)|/$', '', url).split('/')\n    lenLst = len(urlLst)\n    \n    for i in range(lenLst):\n        if i == 0 and lenLst > 1:               ans.append('<a href=\"/\">HOME</a>')\n        elif i != lenLst-1 and len(urlLst) > 2: ans.append('<a href=\"/{}/\">{}</a>'.format( '/'.join(urlLst[1:i+1]), formater(urlLst[i]) ))\n        elif i == lenLst-1:                     ans.append('<span class=\"active\">{}</span>'.format( 'HOME' if i == 0 else formater(re.sub(r'\\..*','',urlLst[-1])) ))\n        \n    return separator.join(ans)", "from re import sub, search\n\ndef generate_bc(url, separator):\n  url = sub(\"https?:\\/\\/\",\"\", sub(\"\\/index\\..+$\",\"\",sub(\"[?#].+$\",\"\", url)))\n  base = search(\".+?\\/\", url).group(0) if search(\".+?\\/\", url) else url\n  #if (base==nil): return '<span class=\"active\">HOME</span>'\n  paths = url[len(base):].split(\"/\")\n  path = \"/\"\n  breadcrumbedPath = ['<a href=\"/\">HOME</a>']\n  if (url==base): return '<span class=\"active\">HOME</span>'\n  classes = None; last = False\n  for i in xrange(len(paths)):\n      if i==len(paths)-1:\n          classes='active'\n          last=True\n      path += paths[i] + \"/\"\n      bcName = paths[i]\n      if len(paths[i])>30: bcName=acronymize(bcName)\n      bcName = parseName(bcName)\n      breadcrumbedPath+=[createHTMLPath(bcName, path, classes, last)]\n  return separator.join(breadcrumbedPath);\n\ncreateHTMLPath=lambda bcName, url, classes, last: ''.join(['<a href=\"',url,'\"',('' if classes==None else ''.join([' class=\"',classes,'\"'])),'>',bcName,'</a>']) if not last else ''.join(['<span',('' if classes==None else ''.join([' class=\"',classes,'\"'])),'>',bcName,'</span>'])\n\nparseName=lambda bcName: sub(\"\\.\\w+\",\"\", \" \".join(bcName.split(\"-\"))).upper()\n\nacronymize=lambda bcName: \"\".join([x[0] for x in bcName.lower().split(\"-\") if x not in [\"the\",\"of\",\"in\",\"from\",\"by\",\"with\",\"and\", \"or\", \"for\", \"to\", \"at\", \"a\"]])", "def generate_bc(url, separator):\n    a, span = '<a href=\"%s/\">%s</a>', '<span class=\"active\">%s</span>'\n    restricted = set(\"THE OF IN FROM BY WITH AND OR FOR TO AT A\".split())\n    def bc(menu):\n        menu = menu.upper().replace('-', ' ')\n        if len(menu) > 30: menu = ''.join(w[0] for w in menu.split() if w not in restricted)\n        return menu or 'HOME'\n    url = ''.join(url.strip('/').rpartition('//')[2].partition('/')[1:]) \\\n            .rsplit('?',1)[0].rsplit('#',1)[0].rsplit('.',1)[0].rsplit('/index')[0].split('/')\n    return separator.join([a % ('/'.join(url[:i]), bc(m)) for i, m in enumerate(url[:-1], 1)] + [span % bc(url[-1])])", "IGNORE = \"THE OF IN FROM BY WITH AND OR FOR TO AT A\".split()\n\ndef generate_bc(url, separator):\n    if url.startswith(\"http\"):\n        url = url.split(\"//\")[1]\n    crumbs = url.split(\"/\")\n    links  = crumbs[1:]\n    crumbs[0] = 'HOME'\n    for i, crumb in enumerate(crumbs):\n        crumb = crumb.split(\".\")[0].split(\"?\")[0].split(\"#\")[0].replace(\"-\", \" \").upper()\n        if len(crumb) > 30:\n            crumb = [c for c in crumb.split() if c not in IGNORE]\n            crumb = ''.join(map(lambda c: c[0], crumb))            \n        crumbs[i] = crumb\n    if crumbs[-1] in ('', 'INDEX'):\n        crumbs.pop()\n    output = []\n    for i, crumb in enumerate(crumbs[:-1]):\n        element = '<a href=\"/%s/\">%s</a>' % (\"/\".join(links[:i]), crumb)\n        output += [element.replace(\"//\", \"/\")]\n    output += ['<span class=\"active\">%s</span>' % crumbs[-1]]\n    return separator.join(output)", "import re\ndef base_name(fullname):\n    return re.sub(r'[.].*$', '', fullname)\n\nignore_words = [\"the\", \"of\", \"in\", \"from\", \"by\", \"with\", \"and\", \"or\", \"for\", \"to\", \"at\", \"a\"]\ndef short_name(name):\n    if len(name) <= 30:\n        return re.sub(r'[-]',' ', name)\n    else:\n        return ''.join([a[0] for a in name.split('-') if a not in ignore_words] )\n\n\ndef generate_bc(url, separator):\n    url_striped = re.sub(r'[#?].*', '',url)\n    url_striped = re.sub(r'(http|https)://', '', url_striped)\n    url_striped = re.sub(r'/$', '', url_striped)\n    url_splited = url_striped.split(\"/\")\n\n    if base_name(url_splited[-1]) == \"index\":\n        del url_splited[-1]\n    if len(url_splited) <= 1:\n        return '<span class=\"active\">HOME</span>'\n\n    path = \"/\"\n    res = list()\n    res.append('<a href=\"/\">HOME</a>')\n    for e in url_splited[1:-1]:\n        path += e + \"/\"\n        res.append('<a href=\"%s\">%s</a>'%(path, short_name(e).upper()))\n    res.append('<span class=\"active\">%s</span>' % (short_name(base_name(url_splited[-1])).upper()))\n\n    return separator.join(res)\n", "from typing import List, Tuple\nfrom urllib.parse import urlparse\nimport re\n\n\ndef generate_bc(url: str, separator: str) -> str:\n    # print(f'url = {repr(url)}')\n    # print(f'separator = {repr(separator)}')\n\n    home_url = '<a href=\"/\">HOME</a>'  # type: str\n\n    (path_components, last_path) = split_url(url)\n    if last_path.startswith(\"index.\"):\n        last_path = ''\n\n    last_path = re.sub(r\"(.html|.htm|.php|.asp)$\", \"\", last_path)\n\n    if not path_components:  # empty\n        if not last_path:\n            return '<span class=\"active\">HOME</span>'\n    elif not last_path:\n        last_path = path_components.pop()\n\n    return separator.join([\n        home_url, *generate_bc_middle(path_components),\n        generate_bc_last(last_path)\n    ])\n\n\ndef generate_bc_middle(path_components: List[str]) -> List[str]:\n    # return ['<a href=\"/important/\">IMPORTANT</a>', '<a href=\"/important/confidential/\">CONFIDENTIAL</a>']\n    cumulative_path = ''\n    result: List[str] = []\n    for path in path_components:\n        cumulative_path = (cumulative_path + '/' +\n                           path) if cumulative_path else path\n        bc = path.replace('-',\n                          ' ').upper() if len(path) <= 30 else acronymyze(path)\n        result.append(f'<a href=\"/{cumulative_path}/\">{bc}</a>')\n    return result\n\n\ndef acronymyze(long_word: str) -> str:\n    \"\"\" Shorten it, acronymizing it\n    (i.e.: taking just the initials of every word) \"\"\"\n    ignore_words = [\n        \"the\", \"of\", \"in\", \"from\", \"by\", \"with\", \"and\", \"or\", \"for\", \"to\",\n        \"at\", \"a\"\n    ]\n    return ''.join(word[0].upper() for word in long_word.split('-')\n                   if word not in ignore_words)\n\n\ndef generate_bc_last(last_path: str) -> str:\n    if len(last_path) > 30:\n        bc = acronymyze(last_path)\n    else:\n        bc = last_path.replace('-', ' ').upper()\n    return f'<span class=\"active\">{bc}</span>'\n\n\ndef split_url(url: str) -> Tuple[List[str], str]:\n    \"\"\" Returns a tuple by splitting the given url\n    url = 'mysite.com/years/pictures/holidays.html'\n    returns a tuple ([years,pictures], 'holidays.html')\n    \"\"\"\n\n    # Example url = 'https://mysite.com/years/pictures/holidays.html'\n    parse_result = urlparse(url)\n    # ParseResult(scheme='https', netloc='mysite.com', path='/years/pictures/holidays.html',\n    #               params='', query='', fragment='')\n\n    # urlparse recognizes a netloc only if it is properly introduced by \u2018//\u2019.\n    # Otherwise the input is presumed to be a relative URL and thus to start\n    # with a path component.\n\n    # Redo urlparse to make sure that parse_result.path has only filepath and not hostpath part\n    if not parse_result.scheme and not url.startswith('//'):\n        parse_result = urlparse('//' + url)\n\n    if not parse_result.path:  # empty path\n        path_components = []\n        last_path = ''\n    elif parse_result.path.startswith('/'):\n        path_components = [\n            component for component in parse_result.path.split(\"/\")\n        ]\n        path_components.pop(0)  # Remove ''\n        # ['', 'years', 'pictures', 'holidays.html']\n        last_path = path_components.pop()  # type: str\n    else:\n        raise Exception(\"Invalid url\")\n\n    # (['years', 'pictures'], 'holidays.html')\n    return (path_components, last_path)\n", "def generate_bc(url, separator):\n    print(url)\n    print(separator)\n    url = str(url.replace(\"https://\", \"\"))\n    url = str(url.replace(\"http://\", \"\"))\n\n    try:\n        questionIndex = url.index(\"?\")\n    except ValueError:\n        questionIndex = -1\n\n    try:\n        hashIndex = url.index(\"#\")\n    except ValueError:\n        hashIndex = -1\n\n    if questionIndex != -1:\n        url = str(url[:questionIndex])\n\n    if hashIndex != -1:\n        url = str(url[:hashIndex])\n\n    names = list(filter(None, url.split('/')))\n    html = \"\"\n\n    commonExtensions = [\".html\", \".htm\", \".php\", \".asp\"]\n    ignoreWords = [\n        \"the\",\n        \"of\",\n        \"in\",\n        \"from\",\n        \"by\",\n        \"with\",\n        \"and\",\n        \"or\",\n        \"for\",\n        \"to\",\n        \"at\",\n        \"a\"\n    ]\n    pastLinks = []\n\n    for index, name in enumerate(names):\n        isFirstIndex = index == 0\n        isLastIndex = index == len(names) - 1\n\n        if not isLastIndex and \"index\" in names[index + 1]:\n            isLastIndex = True\n\n        if isLastIndex:\n            for commonExtension in commonExtensions:\n                name = name.replace(commonExtension, \"\")\n\n        tagValue = \"\"\n        if isFirstIndex:\n            tagValue = \"HOME\"\n        elif len(name) > 30:\n            tagValue = ''.join(\n                str.upper(a[0:1]) for a in name.split('-') if a not in ignoreWords)\n        else:\n            if '-' in name:\n                tagValue = name.upper().replace('-', ' ')\n            else:\n                tagValue = name.upper()\n\n        html += \"<{element}\".format(element='span' if isLastIndex else 'a')\n        if isLastIndex:\n            html += ' class=\"active\"'\n        else:\n            currentLink = name.strip().lower()\n            hrefValue = ''\n            if isFirstIndex:\n                hrefValue = '/'\n            elif len(pastLinks) > 0:\n                pastLinks.append(currentLink)\n                hrefValue = '/{link}/'.format(link=\"/\".join(pastLinks))\n            else:\n                pastLinks.append(currentLink)\n                hrefValue = \"/{link}/\".format(link=currentLink)\n            html += ' href=\"{hrefValue}\"'.format(hrefValue=hrefValue)\n\n        html += '>'\n        html += tagValue\n        html += '</{attribute}>'.format(\n            attribute='span' if isLastIndex else 'a')\n        if not isLastIndex:\n            html += separator\n        if isLastIndex:\n            break\n\n    return html", "import re\n\ndef generate_bc(url, separator):\n    def formater(name):\n        if len(name) > 30:\n            stoplist = ['the','of','in','from','by','with','and','or','for','to','at','a']\n            return ''.join([ch[0].upper() for ch in name.split('-') if ch not in stoplist])\n        else:\n            return name.replace('-', ' ').upper()\n    \n    result = []\n    \n    url = re.sub(r'^https?:\\/\\/', '', url)      # remove protocol\n    url = re.sub(r'\\.[^\\/]*$', '', url)         # remove extensions\n    url = re.sub(r'(?:\\#|\\?).*$', '', url)      # remove anchors and queries\n    url = re.sub(r'index$', '', url)            # remove indexes\n    url = url.rstrip('/')                       # remove trailing slash\n    \n    crumbs = url.split('/')\n    \n    for i, crumb in enumerate(crumbs):\n        if i == 0: result.append('<a href=\"/\">HOME</a>' if len(crumbs) > 1 else '<span class=\"active\">HOME</span>')\n        elif i == len(crumbs) - 1: result.append('<span class=\"active\">{}</span>'.format(formater(crumb)))\n        else: result.append('<a href=\"/{}/\">{}</a>'.format('/'.join(crumbs[1:1+i]), formater(crumb)))\n    \n    return separator.join(result)"]